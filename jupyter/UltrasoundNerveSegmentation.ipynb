{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrasound Nerve Segmentation\n",
    "\n",
    "## Identify nerve structures in ultrasound images of the neck\n",
    "\n",
    "<https://www.kaggle.com/c/ultrasound-nerve-segmentation>\n",
    "\n",
    "> Even the bravest patient cringes at the mention of a surgical procedure. Surgery inevitably brings discomfort, and oftentimes involves significant post-surgical pain. Currently, patient pain is frequently managed through the use of narcotics that bring a bevy of unwanted side effects.\n",
    "This competition's sponsor is working to improve pain management through the use of indwelling catheters that block or mitigate pain at the source. Pain management catheters reduce dependence on narcotics and speed up patient recovery.\n",
    "**Accurately identifying nerve structures in ultrasound images is a critical step in effectively inserting a patientâ€™s pain management catheter.** In this competition, Kagglers are challenged to build a model that can identify nerve structures in a dataset of ultrasound images of the neck. Doing so would improve catheter placement and contribute to a more pain free future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../raw/'\n",
    "\n",
    "image_rows = 420\n",
    "image_cols = 580"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "images = os.listdir(train_data_path)\n",
    "total = len(images) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "i = 0\n",
    "for image_name in tqdm_notebook(images):    \n",
    "    if 'mask' in image_name:\n",
    "        continue\n",
    "        \n",
    "    image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "    img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "    img_mask = imread(os.path.join(train_data_path, image_mask_name), as_grey=True)\n",
    "\n",
    "    img = np.array([img])\n",
    "    img_mask = np.array([img_mask])\n",
    "\n",
    "    imgs[i] = img\n",
    "    imgs_mask[i] = img_mask\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 14))\n",
    "for i in range(4):\n",
    "    sp = f.add_subplot(4, 2, 2*i+1)\n",
    "    sp.axis('Off')\n",
    "    plt.imshow(imgs[i, :, :], cmap=\"gray\")\n",
    "    sp = f.add_subplot(4, 2, 2*i+2)\n",
    "    sp.axis('Off')\n",
    "    plt.imshow(imgs_mask[i, :, :], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = os.path.join(data_path, 'test')\n",
    "images = os.listdir(test_data_path)\n",
    "total = len(images)\n",
    "\n",
    "imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "i = 0\n",
    "for image_name in tqdm_notebook(images):\n",
    "    img_id = int(image_name.split('.')[0])\n",
    "    img = imread(os.path.join(test_data_path, image_name), as_grey=True)\n",
    "\n",
    "    img = np.array([img])\n",
    "\n",
    "    imgs[i] = img\n",
    "    imgs_id[i] = img_id\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 6))\n",
    "for i in range(4):\n",
    "    sp = f.add_subplot(2, 2, i+1)\n",
    "    sp.axis('Off')\n",
    "    sp.set_title(f'ID: {imgs_id[i]}')\n",
    "    plt.imshow(imgs[i, :, :], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = preprocess(imgs_train)\n",
    "imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "mean = np.mean(imgs_train)  # mean for data centering\n",
    "std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "imgs_mask_train /= 255.  # scale masks to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((img_rows, img_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = preprocess(imgs_test)\n",
    "\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test -= mean\n",
    "imgs_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.h5')\n",
    "\n",
    "imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "pred_dir = 'preds'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "    image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "    imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    img = img.astype('float32')\n",
    "    img = (img > 0.5).astype(np.uint8)  # threshold\n",
    "    img = resize(img, (image_cols, image_rows), preserve_range=True)\n",
    "    return img\n",
    "\n",
    "\n",
    "def run_length_enc(label):\n",
    "    from itertools import chain\n",
    "    x = label.transpose().flatten()\n",
    "    y = np.where(x > 0)[0]\n",
    "    if len(y) < 10:  # consider as empty\n",
    "        return ''\n",
    "    z = np.where(np.diff(y) > 1)[0]\n",
    "    start = np.insert(y[z+1], 0, y[0])\n",
    "    end = np.append(y[z], y[-1])\n",
    "    length = end - start\n",
    "    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n",
    "    res = list(chain.from_iterable(res))\n",
    "    return ' '.join([str(r) for r in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsort = np.argsort(imgs_id_test)\n",
    "imgs_id_test = imgs_id_test[argsort]\n",
    "imgs_test = imgs_test[argsort]\n",
    "\n",
    "total = imgs_test.shape[0]\n",
    "ids = []\n",
    "rles = []\n",
    "for i in tqdm_notebook(range(total)):\n",
    "    img = imgs_test[i, 0]\n",
    "    img = prep(img)\n",
    "    rle = run_length_enc(img)\n",
    "\n",
    "    rles.append(rle)\n",
    "    ids.append(imgs_id_test[i])\n",
    "\n",
    "first_row = 'img,pixels'\n",
    "file_name = 'submission.csv'\n",
    "\n",
    "with open(file_name, 'w+') as f:\n",
    "    f.write(first_row + '\\n')\n",
    "    for i in range(total):\n",
    "        s = str(ids[i]) + ',' + rles[i]\n",
    "        f.write(s + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
